{"cells":[{"cell_type":"markdown","metadata":{"id":"Qhvs8xBIo5Ni"},"source":["# **Facial Expression Classificationt**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1695789660475,"user":{"displayName":"Hao Ji","userId":"12290693972539811867"},"user_tz":420},"id":"TCHM5OgVoBKE","outputId":"30c24f9d-e9ae-42fa-e305-db6b32ca801b"},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'train_data.csv'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Read the CSV file into a pandas DataFrame\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(train_labels, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     30\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(test_data, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_data.csv'"]}],"source":["# Facial Expression Classification dataset\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import Module, Conv2d, Linear, MaxPool2d, Dropout, ReLU, LogSoftmax\n","from torch import flatten\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","from sklearn.metrics import classification_report\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","from torch import nn\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import Normalizer, normalize\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","\n","train_data = 'train_data.csv'\n","train_labels = 'train_target.csv'\n","test_data = 'test_data.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","train_data = pd.read_csv(train_data, header=None)\n","train_labels = pd.read_csv(train_labels, header=None)\n","test_data = pd.read_csv(test_data, header=None)\n","\n","# display the top rows\n","train_data.head(10)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\kelz9\\AppData\\Local\\Temp\\ipykernel_29592\\2912847410.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n","  plt.show()\n"]}],"source":["# Definee Training Data\n","train_data_np = train_data.to_numpy()\n","test_data_np = test_data.to_numpy()\n","train_data_np = np.float32(train_data_np)\n","train_labels_np = train_labels.to_numpy()\n","\n","sample_image = np.reshape(train_data_np[0,:], (48,48))\n","\n","plt.imshow(sample_image)\n","plt.show()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Reset model weights to avoid weight leakage\n","def reset_weights(m):\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# Define Convolutional Neural Network\n","class CNN(Module):\n","\tdef __init__(self, numChannels, classes):\n","\t\t# call the parent constructor\n","\t\tsuper(CNN, self).__init__()\n","\t\t# initialize first set of CONV => RELU => POOL layers\n","\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20, kernel_size=(5, 5))\n","\t\tself.relu1 = ReLU()\n","\t\tself.dropout1 = Dropout(0.2)\n","\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv2 = Conv2d(in_channels=20, out_channels=30, kernel_size=(5, 5))\n","\t\tself.relu2 = ReLU()\n","\t\tself.dropout2 = Dropout(0.2)\n","\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv3 = Conv2d(in_channels=30, out_channels=40, kernel_size=(5, 5))\n","\t\tself.relu3= ReLU()\n","\t\tself.dropout3 = Dropout(0.2)\n","\t\tself.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n","\t\t# initialize first (and only) set of FC => RELU layers\n","\t\tself.fc1 = Linear(in_features=5760, out_features=1000)\n","\t\tself.relu4 = ReLU()\n","\t\tself.dropout4 = Dropout(0.2)\n","\t\t# initialize our softmax classifier\n","\t\tself.fc2 = Linear(in_features=1000, out_features=classes)\n","\t\tself.logSoftmax = LogSoftmax(dim=1)\n","\t\t\n","\t# Define forward pass function\n","\tdef forward(self, x):\n","\t\t# pass the input through our first set of CONV => RELU =>\n","\t\t# POOL layers\n","\t\tx = self.conv1(x)\n","\t\tx = self.relu1(x)\n","\t\t#x = self.dropout1(x)\n","\t\tx = self.maxpool1(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv2(x)\n","\t\tx = self.relu2(x)\n","\t\t#x = self.dropout2(x)\n","\t\tx = self.maxpool2(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv3(x)\n","\t\tx = self.relu3(x)\n","\t\t#x = self.dropout3(x)\n","\t\tx = self.maxpool3(x)\n","\t\t# flatten the output from the previous layer and pass it\n","\t\t# through our only set of FC => RELU layers\n","\t\tx = flatten(x, 1)\n","\t\tx = self.fc1(x)\n","\t\tx = self.relu4(x)\n","\t\t#x = self.dropout4(x)\n","\t\t# pass the output to our softmax classifier to get our output\n","\t\t# predictions\n","\t\tx = self.fc2(x)\n","\t\toutput = self.logSoftmax(x)\n","\t\t# return the output predictions\n","\t\treturn output"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class AngularPenaltySMLoss(nn.Module):\n","\n","    def __init__(self, in_features, out_features, loss_type='arcface', eps=1e-7, s=None, m=None):\n","        super(AngularPenaltySMLoss, self).__init__()\n","        loss_type = loss_type.lower()\n","        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n","        if loss_type == 'arcface':\n","            self.s = 64.0 if not s else s\n","            self.m = 0.5 if not m else m\n","        if loss_type == 'sphereface':\n","            self.s = 64.0 if not s else s\n","            self.m = 1.35 if not m else m\n","        if loss_type == 'cosface':\n","            self.s = 30.0 if not s else s\n","            self.m = 0.4 if not m else m\n","        self.loss_type = loss_type\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.fc = nn.Linear(in_features, out_features, bias=False)\n","        self.eps = eps\n","    \n","    def forward(self, x, labels):\n","        '''\n","        input shape (N, in_features)\n","        '''\n","        assert len(x) == len(labels)\n","        assert torch.min(labels) >= 0\n","        assert torch.max(labels)         \n","        for W in self.fc.parameters():\n","            W = F.normalize(W, p=2, dim=1)\n","\n","        x = F.normalize(x, p=2, dim=1)\n","\n","        wf = self.fc(x)\n","        if self.loss_type == 'cosface':\n","            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n","        if self.loss_type == 'arcface':\n","            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n","        if self.loss_type == 'sphereface':\n","            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n","\n","        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n","        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n","        L = numerator - torch.log(denominator)\n","\n","        return -torch.mean(L)\n","      \n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["class ConvAngularPen(nn.Module):\n","    def __init__(self, num_classes=3, loss_type='arcface'):\n","        super(ConvAngularPen, self).__init__()\n","        self.convlayers = CNN(1, 3)\n","        self.adms_loss = AngularPenaltySMLoss(3, num_classes, loss_type=loss_type)\n","\n","    def forward(self, x, labels=None, embed=False):\n","        #x = self.convlayers(x)\n","        if embed:\n","            return x\n","        L = self.adms_loss(x, labels)\n","\n","        return L"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0\n","Reset trainable parameters of layer = Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n","Reset trainable parameters of layer = Conv2d(20, 30, kernel_size=(5, 5), stride=(1, 1))\n","Reset trainable parameters of layer = Conv2d(30, 40, kernel_size=(5, 5), stride=(1, 1))\n","Reset trainable parameters of layer = Linear(in_features=43560, out_features=1000, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=1000, out_features=3, bias=True)\n","0\n"]},{"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (64x5760 and 43560x1000)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[53], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Perform forward pass\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[1;32mIn[52], line 52\u001b[0m, in \u001b[0;36mCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# flatten the output from the previous layer and pass it\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# through our only set of FC => RELU layers\u001b[39;00m\n\u001b[0;32m     51\u001b[0m x \u001b[38;5;241m=\u001b[39m flatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu4(x)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#x = self.dropout4(x)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# pass the output to our softmax classifier to get our output\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# predictions\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\kelz9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x5760 and 43560x1000)"]}],"source":["# define training hyperparameters\n","INIT_LR = 1e-3\n","BATCH_SIZE = 64\n","EPOCHS = 10\n","KFOLDS = 10\n","\n","# For fold results\n","results = {}\n","\n","loss_function = nn.CrossEntropyLoss()\n","\n","# Define the K-fold Cross Validator\n","kfold = KFold(n_splits=KFOLDS, shuffle=True)\n","\n","dataAll = [(((train_data_np[i,:])).reshape(1, 48, 48), train_labels_np[i]) for i in range(train_data_np.shape[0])]\n","\n","for fold, (train_ids, val_ids) in enumerate(kfold.split(dataAll)):\n","    print(fold)\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n","\n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(dataAll, batch_size=BATCH_SIZE, sampler=train_subsampler)\n","    valloader = torch.utils.data.DataLoader(dataAll, batch_size=BATCH_SIZE, sampler=val_subsampler)\n","\n","    # Init the neural network\n","    network = CNN(numChannels=1, classes=3)\n","    network.apply(reset_weights)\n","    \n","    # Initialize optimizer\n","    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4, weight_decay=0.001)\n","\n","    model = ConvAngularPen(loss_type=\"sphereface\")\n","    # Run the training loop for defined number of epochs\n","    for epoch in range(0, EPOCHS):\n","        current_loss = 0\n","        print(epoch)\n","        # Iterate over the DataLoader for training data\n","        for i, data in enumerate(trainloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","            # Zero the gradients\n","            optimizer.zero_grad()\n","            \n","            # Perform forward pass\n","            outputs = network(inputs)\n","            \n","            # Compute loss\n","            loss = loss_function(outputs, targets)\n","            \n","            # Perform backward pass\n","            loss.backward()\n","        \n","            # Perform optimization\n","            optimizer.step()\n","            \n","            # Print statistics\n","            current_loss += loss.item()\n","            if i % 500 == 499:\n","                print('Loss after mini-batch %5d: %.3f' %\n","                    (i + 1, current_loss / 500))\n","                current_loss = 0.0\n","\n","    # Process is complete.\n","    print('Training process has finished.')\n","\n","    # Print about validating\n","    print('Starting validating')\n","\n","    # Evaluationfor this fold\n","    correct, total = 0, 0\n","    correctV, totalV = 0, 0\n","\n","    with torch.no_grad():\n","        # Iterate over the test data and generate predictions\n","        for i, data in enumerate(trainloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","\n","            # Generate outputs\n","            outputs = network(inputs)\n","\n","            # Set total and correct\n","            predicted = torch.max(outputs.data, 1)[1]\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correct / total)\n","\n","    with torch.no_grad():\n","        # Iterate over the test data and generate predictions\n","        for i, data in enumerate(valloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","\n","            # Generate outputs\n","            outputs = network(inputs)\n","\n","            # Set total and correct\n","            predicted = torch.max(outputs.data, 1)[1]\n","            totalV += targets.size(0)\n","            correctV += (predicted == targets).sum().item()\n","\n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correctV / totalV))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correctV / totalV)\n","\n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","    print(f'Fold {key}: {value} %')\n","    sum += value\n","    print(f'Average: {sum/len(results.items())} %')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([2, 0, 1,  ..., 1, 2, 2])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["test_data1 = np.reshape(test_data_np, (test_data_np.shape[0], 1, 48, 48))\n","test_data1 = torch.Tensor(test_data1)\n","# Generate outputs\n","outputs = network(test_data1)\n","\n","# Set total and correct\n","predicted = torch.max(outputs.data, 1)[1]\n","\n","predicted"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["# Create final submission file\n","test_ids = [i for i in range(test_data1.size(0))]\n","\n","final_results = predicted.int()\n","\n","x_np = final_results.numpy()\n","x_df = pd.DataFrame(x_np)\n","x_df.to_csv('sample_subsmission.csv')\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
