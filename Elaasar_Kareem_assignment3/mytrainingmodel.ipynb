{"cells":[{"cell_type":"markdown","metadata":{"id":"Qhvs8xBIo5Ni"},"source":["# **Facial Expression Classificationt**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1695789660475,"user":{"displayName":"Hao Ji","userId":"12290693972539811867"},"user_tz":420},"id":"TCHM5OgVoBKE","outputId":"30c24f9d-e9ae-42fa-e305-db6b32ca801b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>2294</th>\n","      <th>2295</th>\n","      <th>2296</th>\n","      <th>2297</th>\n","      <th>2298</th>\n","      <th>2299</th>\n","      <th>2300</th>\n","      <th>2301</th>\n","      <th>2302</th>\n","      <th>2303</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>146</td>\n","      <td>146</td>\n","      <td>145</td>\n","      <td>145</td>\n","      <td>145</td>\n","      <td>142</td>\n","      <td>140</td>\n","      <td>114</td>\n","      <td>126</td>\n","      <td>128</td>\n","      <td>...</td>\n","      <td>103</td>\n","      <td>103</td>\n","      <td>93</td>\n","      <td>87</td>\n","      <td>73</td>\n","      <td>65</td>\n","      <td>65</td>\n","      <td>76</td>\n","      <td>85</td>\n","      <td>81</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>12</td>\n","      <td>34</td>\n","      <td>72</td>\n","      <td>98</td>\n","      <td>110</td>\n","      <td>113</td>\n","      <td>116</td>\n","      <td>126</td>\n","      <td>134</td>\n","      <td>...</td>\n","      <td>141</td>\n","      <td>121</td>\n","      <td>131</td>\n","      <td>118</td>\n","      <td>93</td>\n","      <td>74</td>\n","      <td>31</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>255</td>\n","      <td>129</td>\n","      <td>62</td>\n","      <td>59</td>\n","      <td>45</td>\n","      <td>31</td>\n","      <td>29</td>\n","      <td>26</td>\n","      <td>32</td>\n","      <td>23</td>\n","      <td>...</td>\n","      <td>122</td>\n","      <td>130</td>\n","      <td>138</td>\n","      <td>113</td>\n","      <td>43</td>\n","      <td>26</td>\n","      <td>16</td>\n","      <td>12</td>\n","      <td>14</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>217</td>\n","      <td>191</td>\n","      <td>222</td>\n","      <td>176</td>\n","      <td>150</td>\n","      <td>201</td>\n","      <td>157</td>\n","      <td>72</td>\n","      <td>59</td>\n","      <td>74</td>\n","      <td>...</td>\n","      <td>223</td>\n","      <td>229</td>\n","      <td>114</td>\n","      <td>70</td>\n","      <td>111</td>\n","      <td>95</td>\n","      <td>71</td>\n","      <td>109</td>\n","      <td>159</td>\n","      <td>191</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>37</td>\n","      <td>62</td>\n","      <td>78</td>\n","      <td>98</td>\n","      <td>113</td>\n","      <td>121</td>\n","      <td>126</td>\n","      <td>...</td>\n","      <td>152</td>\n","      <td>149</td>\n","      <td>156</td>\n","      <td>161</td>\n","      <td>160</td>\n","      <td>158</td>\n","      <td>160</td>\n","      <td>177</td>\n","      <td>187</td>\n","      <td>181</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>232</td>\n","      <td>246</td>\n","      <td>186</td>\n","      <td>23</td>\n","      <td>20</td>\n","      <td>17</td>\n","      <td>...</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","      <td>235</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>230</td>\n","      <td>227</td>\n","      <td>229</td>\n","      <td>229</td>\n","      <td>230</td>\n","      <td>231</td>\n","      <td>233</td>\n","      <td>232</td>\n","      <td>232</td>\n","      <td>232</td>\n","      <td>...</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","      <td>252</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>124</td>\n","      <td>95</td>\n","      <td>79</td>\n","      <td>67</td>\n","      <td>65</td>\n","      <td>57</td>\n","      <td>56</td>\n","      <td>70</td>\n","      <td>76</td>\n","      <td>82</td>\n","      <td>...</td>\n","      <td>99</td>\n","      <td>94</td>\n","      <td>105</td>\n","      <td>123</td>\n","      <td>135</td>\n","      <td>133</td>\n","      <td>123</td>\n","      <td>109</td>\n","      <td>131</td>\n","      <td>144</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>131</td>\n","      <td>162</td>\n","      <td>178</td>\n","      <td>186</td>\n","      <td>192</td>\n","      <td>197</td>\n","      <td>198</td>\n","      <td>200</td>\n","      <td>203</td>\n","      <td>205</td>\n","      <td>...</td>\n","      <td>229</td>\n","      <td>236</td>\n","      <td>230</td>\n","      <td>245</td>\n","      <td>253</td>\n","      <td>252</td>\n","      <td>251</td>\n","      <td>252</td>\n","      <td>251</td>\n","      <td>251</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>41</td>\n","      <td>42</td>\n","      <td>40</td>\n","      <td>45</td>\n","      <td>39</td>\n","      <td>51</td>\n","      <td>79</td>\n","      <td>114</td>\n","      <td>141</td>\n","      <td>146</td>\n","      <td>...</td>\n","      <td>255</td>\n","      <td>254</td>\n","      <td>255</td>\n","      <td>231</td>\n","      <td>129</td>\n","      <td>131</td>\n","      <td>154</td>\n","      <td>203</td>\n","      <td>246</td>\n","      <td>255</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows Ã— 2304 columns</p>\n","</div>"],"text/plain":["   0     1     2     3     4     5     6     7     8     9     ...  2294  \\\n","0   146   146   145   145   145   142   140   114   126   128  ...   103   \n","1     9    12    34    72    98   110   113   116   126   134  ...   141   \n","2   255   129    62    59    45    31    29    26    32    23  ...   122   \n","3   217   191   222   176   150   201   157    72    59    74  ...   223   \n","4    19    11     4    37    62    78    98   113   121   126  ...   152   \n","5   235   235   235   235   232   246   186    23    20    17  ...   235   \n","6   230   227   229   229   230   231   233   232   232   232  ...   252   \n","7   124    95    79    67    65    57    56    70    76    82  ...    99   \n","8   131   162   178   186   192   197   198   200   203   205  ...   229   \n","9    41    42    40    45    39    51    79   114   141   146  ...   255   \n","\n","   2295  2296  2297  2298  2299  2300  2301  2302  2303  \n","0   103    93    87    73    65    65    76    85    81  \n","1   121   131   118    93    74    31     7     4     9  \n","2   130   138   113    43    26    16    12    14    16  \n","3   229   114    70   111    95    71   109   159   191  \n","4   149   156   161   160   158   160   177   187   181  \n","5   235   235   235   235   235   235   235   235   235  \n","6   252   252   252   252   252   252   252   252   252  \n","7    94   105   123   135   133   123   109   131   144  \n","8   236   230   245   253   252   251   252   251   251  \n","9   254   255   231   129   131   154   203   246   255  \n","\n","[10 rows x 2304 columns]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# Facial Expression Classification dataset\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import Module, Conv2d, Linear, MaxPool2d, Dropout, ReLU, LogSoftmax\n","from torch import flatten\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","from sklearn.metrics import classification_report\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","from torch import nn\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import Normalizer, normalize\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","\n","train_data = 'train_data.csv'\n","train_labels = 'train_target.csv'\n","test_data = 'test_data.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","train_data = pd.read_csv(train_data, header=None)\n","train_labels = pd.read_csv(train_labels, header=None)\n","test_data = pd.read_csv(test_data, header=None)\n","\n","# display the top rows\n","train_data.head(10)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Define Training Data\n","train_data_np = train_data.to_numpy()\n","test_data_np = test_data.to_numpy()\n","train_data_np = np.float32(train_data_np)\n","train_labels_np = train_labels.to_numpy()"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Reset model weights to avoid weight leakage\n","def reset_weights(m):\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Define Convolutional Neural Network\n","class CNN(Module):\n","\tdef __init__(self, numChannels, classes):\n","\t\t# call the parent constructor\n","\t\tsuper(CNN, self).__init__()\n","\t\t# initialize first set of CONV => RELU => POOL layers\n","\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20, kernel_size=(5, 5))\n","\t\tself.relu1 = ReLU()\n","\t\tself.dropout1 = Dropout(0.2)\n","\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv2 = Conv2d(in_channels=20, out_channels=30, kernel_size=(5, 5))\n","\t\tself.relu2 = ReLU()\n","\t\tself.dropout2 = Dropout(0.2)\n","\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv3 = Conv2d(in_channels=30, out_channels=40, kernel_size=(5, 5))\n","\t\tself.relu3= ReLU()\n","\t\tself.dropout3 = Dropout(0.2)\n","\t\tself.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n","\t\t# initialize first (and only) set of FC => RELU layers\n","\t\tself.fc1 = Linear(in_features=5760, out_features=1000)\n","\t\tself.relu4 = ReLU()\n","\t\tself.dropout4 = Dropout(0.2)\n","\t\t# initialize our softmax classifier\n","\t\tself.fc2 = Linear(in_features=1000, out_features=classes)\n","\t\tself.logSoftmax = LogSoftmax(dim=1)\n","\t\t\n","\t# Define forward pass function\n","\tdef forward(self, x):\n","\t\t# pass the input through our first set of CONV => RELU =>\n","\t\t# POOL layers\n","\t\tx = self.conv1(x)\n","\t\tx = self.relu1(x)\n","\t\t#x = self.dropout1(x)\n","\t\tx = self.maxpool1(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv2(x)\n","\t\tx = self.relu2(x)\n","\t\t#x = self.dropout2(x)\n","\t\tx = self.maxpool2(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv3(x)\n","\t\tx = self.relu3(x)\n","\t\t#x = self.dropout3(x)\n","\t\tx = self.maxpool3(x)\n","\t\t# flatten the output from the previous layer and pass it\n","\t\t# through our only set of FC => RELU layers\n","\t\tx = flatten(x, 1)\n","\t\tx = self.fc1(x)\n","\t\tx = self.relu4(x)\n","\t\t#x = self.dropout4(x)\n","\t\t# pass the output to our softmax classifier to get our output\n","\t\t# predictions\n","\t\tx = self.fc2(x)\n","\t\toutput = self.logSoftmax(x)\n","\t\t# return the output predictions\n","\t\treturn output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define training hyperparameters\n","INIT_LR = 1e-3\n","BATCH_SIZE = 64\n","EPOCHS = 10\n","KFOLDS = 10\n","\n","# For fold results\n","results = {}\n","\n","loss_function = nn.CrossEntropyLoss()\n","\n","# Define the K-fold Cross Validator\n","kfold = KFold(n_splits=KFOLDS, shuffle=True)\n","\n","dataAll = [(((train_data_np[i,:])).reshape(1, 48, 48), train_labels_np[i]) for i in range(train_data_np.shape[0])]\n","\n","for fold, (train_ids, val_ids) in enumerate(kfold.split(dataAll)):\n","    print(fold)\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n","\n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(dataAll, batch_size=BATCH_SIZE, sampler=train_subsampler)\n","    valloader = torch.utils.data.DataLoader(dataAll, batch_size=BATCH_SIZE, sampler=val_subsampler)\n","\n","    # Init the neural network\n","    network = CNN(numChannels=1, classes=3)\n","    network.apply(reset_weights)\n","    \n","    # Initialize optimizer\n","    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4, weight_decay=0.001)\n","\n","    # Run the training loop for defined number of epochs\n","    for epoch in range(0, EPOCHS):\n","        current_loss = 0\n","        print(epoch)\n","        # Iterate over the DataLoader for training data\n","        for i, data in enumerate(trainloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","            # Zero the gradients\n","            optimizer.zero_grad()\n","            \n","            # Perform forward pass\n","            outputs = network(inputs)\n","            \n","            # Compute loss\n","            loss = loss_function(outputs, targets)\n","            \n","            # Perform backward pass\n","            loss.backward()\n","        \n","            # Perform optimization\n","            optimizer.step()\n","            \n","            # Print statistics\n","            current_loss += loss.item()\n","            if i % 500 == 499:\n","                print('Loss after mini-batch %5d: %.3f' %\n","                    (i + 1, current_loss / 500))\n","                current_loss = 0.0\n","\n","    # Process is complete.\n","    print('Training process has finished.')\n","\n","    # Print about validating\n","    print('Starting validating')\n","\n","    # Evaluationfor this fold\n","    correct, total = 0, 0\n","    correctV, totalV = 0, 0\n","\n","    with torch.no_grad():\n","        # Iterate over the test data and generate predictions\n","        for i, data in enumerate(trainloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","\n","            # Generate outputs\n","            outputs = network(inputs)\n","\n","            # Set total and correct\n","            predicted = torch.max(outputs.data, 1)[1]\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correct / total)\n","\n","    with torch.no_grad():\n","        # Iterate over the test data and generate predictions\n","        for i, data in enumerate(valloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","\n","            # Generate outputs\n","            outputs = network(inputs)\n","\n","            # Set total and correct\n","            predicted = torch.max(outputs.data, 1)[1]\n","            totalV += targets.size(0)\n","            correctV += (predicted == targets).sum().item()\n","\n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correctV / totalV))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correctV / totalV)\n","\n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","    print(f'Fold {key}: {value} %')\n","    sum += value\n","    print(f'Average: {sum/len(results.items())} %')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([2, 0, 1,  ..., 1, 2, 2])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["test_data1 = np.reshape(test_data_np, (test_data_np.shape[0], 1, 48, 48))\n","test_data1 = torch.Tensor(test_data1)\n","\n","# Generate outputs\n","outputs = network(test_data1)\n","\n","# Set total and correct\n","predicted = torch.max(outputs.data, 1)[1]"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["# Create final submission file\n","test_ids = [i for i in range(test_data1.size(0))]\n","\n","final_results = predicted.int()\n","\n","x_np = final_results.numpy()\n","x_df = pd.DataFrame(x_np)\n","x_df.to_csv('sample_subsmission.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
