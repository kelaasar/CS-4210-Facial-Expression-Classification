{"cells":[{"cell_type":"markdown","metadata":{"id":"Qhvs8xBIo5Ni"},"source":["# **Facial Expression Classificationt**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":684,"status":"ok","timestamp":1695789660475,"user":{"displayName":"Hao Ji","userId":"12290693972539811867"},"user_tz":420},"id":"TCHM5OgVoBKE","outputId":"30c24f9d-e9ae-42fa-e305-db6b32ca801b"},"outputs":[],"source":["# Facial Expression Classification dataset\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.nn import Module, Conv2d, Linear, MaxPool2d, Dropout, ReLU, LogSoftmax\n","from torch import flatten\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","from sklearn.metrics import classification_report\n","from torch.utils.data import random_split\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam\n","from torch import nn\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import Normalizer, normalize\n","import matplotlib\n","matplotlib.use('Agg')\n","\n","\n","train_data = 'train_data.csv'\n","train_labels = 'train_target.csv'\n","test_data = 'test_data.csv'\n","\n","# Read the CSV file into a pandas DataFrame\n","train_data = pd.read_csv(train_data, header=None)\n","train_labels = pd.read_csv(train_labels, header=None)\n","test_data = pd.read_csv(test_data, header=None)\n","\n","# display the top rows\n","train_data.head(10)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\kelz9\\AppData\\Local\\Temp\\ipykernel_29592\\2912847410.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n","  plt.show()\n"]}],"source":["# Definee Training Data\n","train_data_np = train_data.to_numpy()\n","test_data_np = test_data.to_numpy()\n","train_data_np = np.float32(train_data_np)\n","train_labels_np = train_labels.to_numpy()\n","\n","sample_image = np.reshape(train_data_np[0,:], (48,48))\n","\n","plt.imshow(sample_image)\n","plt.show()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# Reset model weights to avoid weight leakage\n","def reset_weights(m):\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["# Define Convolutional Neural Network\n","class CNN(Module):\n","\tdef __init__(self, numChannels, classes):\n","\t\t# call the parent constructor\n","\t\tsuper(CNN, self).__init__()\n","\t\t# initialize first set of CONV => RELU => POOL layers\n","\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20, kernel_size=(5, 5))\n","\t\tself.relu1 = ReLU()\n","\t\tself.dropout1 = Dropout(0.2)\n","\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv2 = Conv2d(in_channels=20, out_channels=30, kernel_size=(5, 5))\n","\t\tself.relu2 = ReLU()\n","\t\tself.dropout2 = Dropout(0.2)\n","\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n","\t\t# initialize second set of CONV => RELU => POOL layers\n","\t\tself.conv3 = Conv2d(in_channels=30, out_channels=40, kernel_size=(5, 5))\n","\t\tself.relu3= ReLU()\n","\t\tself.dropout3 = Dropout(0.2)\n","\t\tself.maxpool3 = MaxPool2d(kernel_size=(2, 2), stride=(1, 1))\n","\t\t# initialize first (and only) set of FC => RELU layers\n","\t\tself.fc1 = Linear(in_features=5760, out_features=1000)\n","\t\tself.relu4 = ReLU()\n","\t\tself.dropout4 = Dropout(0.2)\n","\t\t# initialize our softmax classifier\n","\t\tself.fc2 = Linear(in_features=1000, out_features=classes)\n","\t\tself.logSoftmax = LogSoftmax(dim=1)\n","\t\t\n","\t# Define forward pass function\n","\tdef forward(self, x):\n","\t\t# pass the input through our first set of CONV => RELU =>\n","\t\t# POOL layers\n","\t\tx = self.conv1(x)\n","\t\tx = self.relu1(x)\n","\t\t#x = self.dropout1(x)\n","\t\tx = self.maxpool1(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv2(x)\n","\t\tx = self.relu2(x)\n","\t\t#x = self.dropout2(x)\n","\t\tx = self.maxpool2(x)\n","\t\t# pass the output from the previous layer through the second\n","\t\t# set of CONV => RELU => POOL layers\n","\t\tx = self.conv3(x)\n","\t\tx = self.relu3(x)\n","\t\t#x = self.dropout3(x)\n","\t\tx = self.maxpool3(x)\n","\t\t# flatten the output from the previous layer and pass it\n","\t\t# through our only set of FC => RELU layers\n","\t\tx = flatten(x, 1)\n","\t\tx = self.fc1(x)\n","\t\tx = self.relu4(x)\n","\t\t#x = self.dropout4(x)\n","\t\t# pass the output to our softmax classifier to get our output\n","\t\t# predictions\n","\t\tx = self.fc2(x)\n","\t\toutput = self.logSoftmax(x)\n","\t\t# return the output predictions\n","\t\treturn output"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class AngularPenaltySMLoss(nn.Module):\n","\n","    def __init__(self, in_features, out_features, loss_type='arcface', eps=1e-7, s=None, m=None):\n","        super(AngularPenaltySMLoss, self).__init__()\n","        loss_type = loss_type.lower()\n","        assert loss_type in  ['arcface', 'sphereface', 'cosface']\n","        if loss_type == 'arcface':\n","            self.s = 64.0 if not s else s\n","            self.m = 0.5 if not m else m\n","        if loss_type == 'sphereface':\n","            self.s = 64.0 if not s else s\n","            self.m = 1.35 if not m else m\n","        if loss_type == 'cosface':\n","            self.s = 30.0 if not s else s\n","            self.m = 0.4 if not m else m\n","        self.loss_type = loss_type\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.fc = nn.Linear(in_features, out_features, bias=False)\n","        self.eps = eps\n","    \n","    def forward(self, x, labels):\n","        '''\n","        input shape (N, in_features)\n","        '''\n","        assert len(x) == len(labels)\n","        assert torch.min(labels) >= 0\n","        assert torch.max(labels)         \n","        for W in self.fc.parameters():\n","            W = F.normalize(W, p=2, dim=1)\n","\n","        x = F.normalize(x, p=2, dim=1)\n","\n","        wf = self.fc(x)\n","        if self.loss_type == 'cosface':\n","            numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n","        if self.loss_type == 'arcface':\n","            numerator = self.s * torch.cos(torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)) + self.m)\n","        if self.loss_type == 'sphereface':\n","            numerator = self.s * torch.cos(self.m * torch.acos(torch.clamp(torch.diagonal(wf.transpose(0, 1)[labels]), -1.+self.eps, 1-self.eps)))\n","\n","        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n","        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n","        L = numerator - torch.log(denominator)\n","\n","        return -torch.mean(L)\n","      \n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["class ConvAngularPen(nn.Module):\n","    def __init__(self, num_classes=3, loss_type='arcface'):\n","        super(ConvAngularPen, self).__init__()\n","        self.convlayers = CNN(1, 3)\n","        self.adms_loss = AngularPenaltySMLoss(3, num_classes, loss_type=loss_type)\n","\n","    def forward(self, x, labels=None, embed=False):\n","        #x = self.convlayers(x)\n","        if embed:\n","            return x\n","        L = self.adms_loss(x, labels)\n","\n","        return L"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# define training hyperparameters\n","INIT_LR = 1e-3\n","BATCH_SIZE = 64\n","EPOCHS = 10\n","KFOLDS = 10\n","\n","# For fold results\n","results = {}\n","\n","loss_function = nn.CrossEntropyLoss()\n","\n","# Define the K-fold Cross Validator\n","kfold = KFold(n_splits=KFOLDS, shuffle=True)\n","\n","dataAll = [(((train_data_np[i,:])).reshape(1, 48, 48), train_labels_np[i]) for i in range(train_data_np.shape[0])]\n","\n","for fold, (train_ids, val_ids) in enumerate(kfold.split(dataAll)):\n","    print(fold)\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n","\n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(dataAll, batch_size=BATCH_SIZE, sampler=train_subsampler)\n","    valloader = torch.utils.data.DataLoader(dataAll, batch_size=BATCH_SIZE, sampler=val_subsampler)\n","\n","    # Init the neural network\n","    network = CNN(numChannels=1, classes=3)\n","    network.apply(reset_weights)\n","    \n","    # Initialize optimizer\n","    optimizer = torch.optim.Adam(network.parameters(), lr=1e-4, weight_decay=0.001)\n","\n","    model = ConvAngularPen(loss_type=\"sphereface\")\n","    # Run the training loop for defined number of epochs\n","    for epoch in range(0, EPOCHS):\n","        current_loss = 0\n","        print(epoch)\n","        # Iterate over the DataLoader for training data\n","        for i, data in enumerate(trainloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","            # Zero the gradients\n","            optimizer.zero_grad()\n","            \n","            # Perform forward pass\n","            outputs = network(inputs)\n","            \n","            # Compute loss\n","            loss = loss_function(outputs, targets)\n","            \n","            # Perform backward pass\n","            loss.backward()\n","        \n","            # Perform optimization\n","            optimizer.step()\n","            \n","            # Print statistics\n","            current_loss += loss.item()\n","            if i % 500 == 499:\n","                print('Loss after mini-batch %5d: %.3f' %\n","                    (i + 1, current_loss / 500))\n","                current_loss = 0.0\n","\n","    # Process is complete.\n","    print('Training process has finished.')\n","\n","    # Print about validating\n","    print('Starting validating')\n","\n","    # Evaluationfor this fold\n","    correct, total = 0, 0\n","    correctV, totalV = 0, 0\n","\n","    with torch.no_grad():\n","        # Iterate over the test data and generate predictions\n","        for i, data in enumerate(trainloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","\n","            # Generate outputs\n","            outputs = network(inputs)\n","\n","            # Set total and correct\n","            predicted = torch.max(outputs.data, 1)[1]\n","            total += targets.size(0)\n","            correct += (predicted == targets).sum().item()\n","\n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correct / total)\n","\n","    with torch.no_grad():\n","        # Iterate over the test data and generate predictions\n","        for i, data in enumerate(valloader, 0):\n","            # Get inputs\n","            inputs, targets = data\n","            targets = torch.flatten(targets)            \n","\n","            # Generate outputs\n","            outputs = network(inputs)\n","\n","            # Set total and correct\n","            predicted = torch.max(outputs.data, 1)[1]\n","            totalV += targets.size(0)\n","            correctV += (predicted == targets).sum().item()\n","\n","    # Print accuracy\n","    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correctV / totalV))\n","    print('--------------------------------')\n","    results[fold] = 100.0 * (correctV / totalV)\n","\n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","    print(f'Fold {key}: {value} %')\n","    sum += value\n","    print(f'Average: {sum/len(results.items())} %')"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([2, 0, 1,  ..., 1, 2, 2])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["test_data1 = np.reshape(test_data_np, (test_data_np.shape[0], 1, 48, 48))\n","test_data1 = torch.Tensor(test_data1)\n","# Generate outputs\n","outputs = network(test_data1)\n","\n","# Set total and correct\n","predicted = torch.max(outputs.data, 1)[1]\n","\n","predicted"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["# Create final submission file\n","test_ids = [i for i in range(test_data1.size(0))]\n","\n","final_results = predicted.int()\n","\n","x_np = final_results.numpy()\n","x_df = pd.DataFrame(x_np)\n","x_df.to_csv('sample_subsmission.csv')\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
